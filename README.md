# Snowflake-ETL-Pipeline
This project will walk you through building an end-to-end data pipeline from an external data source into Snowflake, transforming the data, and loading it into Snowflake's Data Warehouse.


**Project Title: Building an ETL Pipeline in Snowflake**

**Project Overview:**
The goal of this project is to build an automated ETL (Extract, Transform, Load) pipeline using Snowflake to integrate data from an external source (e.g., CSV file,Oracle, Sql server, REST API (heterogenous data sources), transform it, and load it into a Snowflake Data Warehouse. The process will use cloud-native tools such as Snowflake, and SQL for data transformation.

**Phase 1**
Requirements Gathering & Analysis

**Phase 2**
ETL pipeline Design

**Phase 3**
Snowflake Data Model Design 

**Phase 4**
Job Creation and Scheduling

**Phase 5**
Data Validation and testing

**Phase 6**
Deployment and Monitoring

**Note: **Document the ETL pipeline, including source-to-target mappings, transformation logic, and job dependencies.Prepare a documentation for running and maintaining the ETL pipeline

